# AIS-Intern
Python, Data Analysis


Day 1:

1. Variable Selection : Learn how to select and use variables in Python.
   
2. Operations : Understand basic operations we can perform with variables(like addition +, subtraction -, multiplication *, and division /), comparison (like equal ==, not equal !=, greater than >, and less than <), and logical (like and and, or or, not not).

3. List : Learn how to use lists to store multiple items in a single variable.

4. Tuple : Understand the use of tuples to store multiple items that cannot be changed.

5. Set : Learn how to use sets to store unique items.

6. Dictionary : Understand how to use dictionaries to store key-value pairs.


Day 2: 

1. If condition : Learn how to execute code based on a condition.

2. If else condition : Understand how to execute code when a condition is true and another block of code when it is false.

3. If elif condition : Learn how to handle multiple conditions.

4. for loop : Understand how to repeat a block of code a specific number of times.

5. While loop : Learn how to repeat a block of code as long as a condition is true.

Day 3: 

1. Break Statement : Learn how to exit a loop prematurely.

2. Pass Statement : Understand how to create a placeholder for future code.

3. Continue Statement : Learn how to skip the rest of the code inside a loop for the current iteration and move to the next iteration.

4. Statistical User Define Functions : Understand how to create functions that perform statistical operations.

5. Logical User Define Functions : Learn how to create functions that perform logical operations.

Day 4:

1. NumPy Library : Learn how to use the NumPy library for numerical computing in Python.

2. Random Number Generation : Understand how to generate random numbers and work with random variables using NumPy.

Day 5: 

Pandas Library : Learn how to use the Pandas library for data manipulation and analysis in Python.


Day 6: 

Seaborn and Matplotlib :
Seaborn : Learn advanced data visualization and statistical plotting using Seaborn in Python.

Matplotlib : Learn how to visualize data using Matplotlib in Python.

Day 7: 

NumPy Exercise : Practice using NumPy for various numerical computing tasks.

Day 8: 

Ecommerce Purchase Exercise : To analyze eCommerce purchase data using Python and Pandas for insights.

Day 9:

SF Salaries Exercise : To analyze SF city employee salary data using Python and Pandas for insights such as top earners, low earners and job trends.

Day 10 :

Case Study : Titanic Dataset

1. Explore the structure of the dataset, including columns, data types, and summary statistics.
2. Data Cleaning and Preparation : Handle missing values by imputation or removal.
3. Convert categorical variables into numerical representations if necessary.
4. Selecting an appropriate machine learning algorithm (e.g., linear regression, decision tree) based on the problem and data characteristics.
5. Using training data to adjust the model's parameters so that it can make classifications based on the input features.

Day 11 : 

Project :- "Box Office Revenue Prediction"

1. Data Preparation:
   Reading Data :
   we load our dataset and import the necessary libraries for data analysis.

   Data Cleaning :
   we check for missing values and fill them or drop them.

   Variable Selection :
   we remove any unnecessary variables that wouldn't help in our prediction.

   Label Encoding :
   For any categorical variables (like movie genres), we converted them into       
   numerical values that our models could understand.
   
Day 15 :

2. Visualization :
   Using Power BI, we created a dashboard to visualize the data. This helped us 
   understand trends and patterns through different graphs and charts.
   
Day 19 :

3. Model Building :
   Our goal is to predict box office revenue(a continuous variable), so we used 
   various regression techniques, such as:
   
   1. Linear Regression
   2. K - Nearest Neighbors(KNN)
   3. Decision Tree
   4. Random Forest
   5. Bagging
   6. Boosting
   7. Support Vector Regression(SVR)
   8. Neural Networks
   9. Voting
   10. Stacking
  
      We trained our models using all these techniques and then applied Grid Search 
   Cross-Validation (Grid Search CV) to fine-tune the parameters and improve 
   performance.
   
Day 25 :

4. Feature Selection :
   We identified and selected the most important features using Random Forest method.
   After selecting most importan features we apply all model building techniques on 
   the data.
   
5. Result :
   After comparing the Root Mean Squared Errors (RMSE) of all models, we found that 
   the Linear Regression model had the lowest RMSE.
   This means the Linear Regression model made the most accurate predictions, so we 
   chose it as our best model for predicting box office revenue.

Day 28 :
   Presentation of the project.
